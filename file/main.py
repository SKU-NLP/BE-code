import pandas as pd
import numpy as np
import ast
import re
import os

from sentence_transformers import SentenceTransformer
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI
from dotenv import load_dotenv

# ======================================================
# 0. ê¸°ë³¸ ì„¤ì •
# ======================================================
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI(title="ë§¥ë½ + ì„±ì  + í•™êµí‰ì  ê¸°ë°˜ ëŒ€í•™ ì¶”ì²œ API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ======================================================
# 1. í…ìŠ¤íŠ¸ ì •ê·œí™”
# ======================================================
def normalize_text(text: str) -> str:
    text = str(text)
    text = re.sub(r"[,\u00b7ãƒ»]", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

# ======================================================
# 2. ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë‚´ì‹  ì¶”ì¶œ
# ======================================================
def extract_grade(text: str):
    match = re.search(r"(?:ë‚´ì‹ \s*)?(\d(?:\.\d+)?)", text)
    return float(match.group(1)) if match else None

# ======================================================
# 3. ë°ì´í„° ë¡œë”©
# ======================================================
print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")

# í•™ê³¼ ì •ë³´
info_df = pd.read_csv("A_embedding.csv").fillna("")
info_df.columns = info_df.columns.str.strip()

# ì„ë² ë”©
emb_df = pd.read_csv("A_embedding_vectors.csv")
emb_df["embedding"] = emb_df["embedding"].apply(
    lambda x: np.array(ast.literal_eval(x))
)

# í•™ê³¼ í‰ê·  ë‚´ì‹ 
score_df = pd.read_csv("A_score.csv").fillna("")
score_df.columns = score_df.columns.str.strip()

# ğŸ”¥ í•™êµ í‰ì 
school_df = pd.read_csv("school_score.csv").fillna("")
school_df.columns = (
    school_df.columns
    .str.replace("\n", "", regex=False)
    .str.replace(" ", "", regex=False)
)

school_df = school_df.rename(columns={
    "í•™ë¬¸ì í‰íŒì ìˆ˜í•™ê³„ì—ì„œì–¼ë§ˆë‚˜ì¸ì •ë°›ëŠ”ëŒ€í•™ì¸ê°€": "í•™ë¬¸ì í‰íŒì ìˆ˜",
    "ì·¨ì—…í‰íŒì ìˆ˜ê¸°ì—…ì´ì„ í˜¸ë‚˜ëŠ”í•™êµì¸ê°€": "ì·¨ì—…í‰íŒì ìˆ˜",
    "êµìœ¡ë°€ë„êµìˆ˜ìˆ˜ëŒ€ë¹„í•™ìƒìˆ˜.í•™ìƒí•œëª…ì´êµìˆ˜ì—ê²Œì–¼ë§ˆë‚˜ì§‘ì¤‘ì§€ë„ë¥¼ë°›ì„ìˆ˜ìˆëŠ”ê°€": "êµìœ¡ë°€ë„",
    "êµìˆ˜ë‹¹ë…¼ë¬¸ì¸ìš©ìˆ˜êµìˆ˜ì˜ì§ˆ.": "êµìˆ˜ë‹¹ë…¼ë¬¸ì¸ìš©ìˆ˜",
    "êµ­ì œê³µë™ì—°êµ¬ìœ í•™í•´ì™¸ì—°êµ¬ê¸€ë¡œë²Œì§„ì¶œì—°ê²°ì„±": "êµ­ì œê³µë™ì—°êµ¬",
    "ì¡¸ì—…ìƒì„±ê³¼ì·¨ì—…ë¥ ì¡¸ì—…ìƒì—": "ì¡¸ì—…ìƒì„±ê³¼",
})

# ë³‘í•©
info_df["embedding"] = emb_df["embedding"].values
corpus_embeddings = np.vstack(info_df["embedding"].values)

# ì§€ì—­
if "ì†Œì¬ì§€(ìƒì„¸)" in info_df.columns:
    info_df["ì§€ì—­"] = info_df["ì†Œì¬ì§€(ìƒì„¸)"]
else:
    info_df["ì§€ì—­"] = info_df.get("ì†Œì¬ì§€", "")

model = SentenceTransformer("intfloat/multilingual-e5-base")

print("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ")

# ======================================================
# 4. ì„ë² ë”© ê¸°ë°˜ í•™ê³¼ ê²€ìƒ‰
# ======================================================
def search_major_contextual(user_query: str, top_k: int = 8):
    query_emb = model.encode(
        "query: " + normalize_text(user_query),
        convert_to_numpy=True,
        normalize_embeddings=True
    )

    df = info_df.copy()
    df["sim"] = np.dot(corpus_embeddings, query_emb)
    results = df.sort_values("sim", ascending=False).head(top_k)

    if results.empty or results.iloc[0]["sim"] < 0.65:
        return pd.DataFrame()

    return results

# ======================================================
# 5. ì„±ì  + í•™êµ í‰ì  ë§¤ì¹­
# ======================================================
def attach_score(results_df: pd.DataFrame, user_grade: float):
    rows = []

    for _, row in results_df.iterrows():
        score_row = score_df[
            (score_df["ëŒ€í•™ëª…"] == row["ëŒ€í•™ëª…"]) &
            (score_df["í•™ê³¼ëª…"] == row["í•™ê³¼ëª…"])
        ]
        if score_row.empty:
            continue

        try:
            avg = float(score_row.iloc[0]["í•™ì "])
        except:
            continue

        # ğŸ”¥ ë‚´ì‹  ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬
        if user_grade >= avg + 0.2:
            level = "ìƒí–¥"
        elif user_grade <= avg - 0.2:
            level = "í•˜í–¥"
        else:
            level = "ì ì •"

        school_row = school_df[school_df["í•™êµ"] == row["ëŒ€í•™ëª…"]]
        school = school_row.iloc[0] if not school_row.empty else {}

        rows.append({
            "ëŒ€í•™ëª…": row["ëŒ€í•™ëª…"],
            "í•™ê³¼ëª…": row["í•™ê³¼ëª…"],
            "ì§€ì—­": row["ì§€ì—­"],
            "í‰ê· ë‚´ì‹ ": avg,
            "íŒë‹¨": level,

            "í•™ë¬¸í‰íŒ": school.get("í•™ë¬¸ì í‰íŒì ìˆ˜"),
            "ì·¨ì—…í‰íŒ": school.get("ì·¨ì—…í‰íŒì ìˆ˜"),
            "êµìœ¡ë°€ë„": school.get("êµìœ¡ë°€ë„"),
            "êµìˆ˜ì—°êµ¬ë ¥": school.get("êµìˆ˜ë‹¹ë…¼ë¬¸ì¸ìš©ìˆ˜"),
            "êµ­ì œí™”": school.get("êµ­ì œê³µë™ì—°êµ¬"),
            "ì¡¸ì—…ì„±ê³¼": school.get("ì¡¸ì—…ìƒì„±ê³¼"),
            "í•™êµìˆœìœ„": school.get("ìˆœìœ„"),
        })

    return pd.DataFrame(rows)

# ======================================================
# 6. GPT í”„ë¡¬í”„íŠ¸
# ======================================================
def build_hybrid_prompt(user_query, user_grade, rec_df):
    context = ""

    for idx, r in rec_df.iterrows():
        context += f"""
[{idx+1}] {r['ëŒ€í•™ëª…']} {r['í•™ê³¼ëª…']} ({r['íŒë‹¨']})
- í‰ê·  ë‚´ì‹ : {r['í‰ê· ë‚´ì‹ ']}
- í•™êµ í‰ê°€
  Â· í•™ë¬¸ì  í‰íŒ ì ìˆ˜: {r['í•™ë¬¸í‰íŒ']}
  Â· ì·¨ì—… í‰íŒ ì ìˆ˜: {r['ì·¨ì—…í‰íŒ']}
  Â· êµìœ¡ ë°€ë„: {r['êµìœ¡ë°€ë„']}
  Â· êµìˆ˜ ì—°êµ¬ë ¥: {r['êµìˆ˜ì—°êµ¬ë ¥']}
  Â· êµ­ì œí™” ìˆ˜ì¤€: {r['êµ­ì œí™”']}
  Â· ì¡¸ì—… ì„±ê³¼: {r['ì¡¸ì—…ì„±ê³¼']}
"""
    return f"""
ë„ˆëŠ” í•œêµ­ ëŒ€í•™ ì…ì‹œ ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì´ë‹¤.

[ì‚¬ìš©ì ì •ë³´]
- ì§ˆë¬¸: {user_query}
- ë‚´ì‹ : {user_grade}

[ì¶”ì²œ ê²°ê³¼]
ì•„ë˜ ëª¨ë“  ì¶”ì²œ í•­ëª©ì— ëŒ€í•´
â‘  ë‚´ì‹  ì í•©ë„
â‘¡ í•™êµ í‰ê°€ ì§€í‘œ
â‘¢ ì™œ ì´ í•™ìƒì—ê²Œ ì í•©í•œì§€
ë¥¼ **ë°˜ë“œì‹œ ëª¨ë‘ í¬í•¨í•´ì„œ ì„¤ëª…í•´ë¼.**

{context if context else "ì¡°ê±´ì— ë§ëŠ” ì¶”ì²œì´ ë¶€ì¡±í•¨"}

[ì¶œë ¥ ê·œì¹™ â€” ë§¤ìš° ì¤‘ìš”]
- ëª¨ë“  ì¶”ì²œ ë²ˆí˜¸ë§ˆë‹¤ ë°˜ë“œì‹œ **í•™êµ í‰ê°€ í•­ëª©ì„ ì „ë¶€ ì„¤ëª…**
- ì ˆëŒ€ë¡œ ì²« ë²ˆì§¸ë§Œ ìì„¸íˆ ì„¤ëª…í•˜ê³  ë‚˜ë¨¸ì§€ë¥¼ ìƒëµí•˜ì§€ ë§ˆë¼
- ê° í•™êµë¥¼ ë¹„êµÂ·ë¶„ì„í•˜ëŠ” ë§íˆ¬ë¡œ ì„¤ëª…í•´ë¼
- ìƒë‹´ ì„ ìƒë‹˜ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´ë¼
"""

# ======================================================
# 7. API
# ======================================================
class ChatRequest(BaseModel):
    question: str

@app.post("/chat")
def chat(req: ChatRequest):
    user_grade = extract_grade(req.question)
    majors = search_major_contextual(req.question)

    rec_df = (
        attach_score(majors, user_grade)
        if user_grade is not None and not majors.empty
        else pd.DataFrame()
    )

    prompt = build_hybrid_prompt(req.question, user_grade, rec_df)

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì…ì‹œ ìƒë‹´ ì „ë¬¸ê°€ë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.5
    )

    return {
        "answer": response.choices[0].message.content,
        "matched_count": len(rec_df)
    }
